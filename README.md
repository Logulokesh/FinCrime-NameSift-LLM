<h1 align="center">ğŸ›¡ï¸ FinCrime NameSift LLM</h1>

<p align="center"><em>Advanced AI-Powered Financial Crime Detection & Name Screening Platform</em></p>

<p align="center">
  Transform your compliance operations with <strong>FinCrime-NameSift-LLM</strong>, the cutting-edge screening platform that combines machine learning, natural language processing, and vector-based similarity matching to identify high-risk entities in real-time. Built for financial institutions, fintech companies, and compliance teams who demand precision and speed in combating financial crime. ğŸ¯
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Backend-FastAPI-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Frontend-Streamlit-ff4b4b?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Database-PostgreSQL-informational?style=for-the-badge" />
  <img src="https://img.shields.io/badge/LLM-Ollama-orange?style=for-the-badge" />
</p>

---

## âœ¨ Core Capabilities & Features

### ğŸ” **Intelligent Screening Engine**
- âš¡ **Real-time Processing**: Lightning-fast customer screening with sub-second response times
- ğŸ§  **Fuzzy Matching**: Advanced name matching algorithms that catch variations and misspellings
- ğŸ“Š **Dynamic Risk Scoring**: AI-generated risk assessments with confidence intervals
- ğŸ¯ **Multi-dimensional Analysis**: Cross-reference names, DOB, nationality, and aliases

### ğŸ“‹ **Watchlist Management Suite**
- ğŸ“¤ **Multi-format Ingestion**: Support for CSV, JSON, and ISO 20022 XML (MX) standards
- ğŸ”„ **Bulk Processing**: Handle thousands of watchlist entries simultaneously
- ğŸ·ï¸ **Smart Categorization**: Automatic classification of PEPs, sanctions, and adverse media
- ğŸ“ˆ **Data Validation**: Built-in checks for data integrity and completeness

### ğŸ¤– **AI-Powered Analytics**
- ğŸ’¡ **LLM Risk Explanations**: Natural language explanations for every match
- ğŸ“Š **Confidence Scoring**: Probability-based matching with tunable thresholds
- ğŸ”® **Predictive Insights**: Trend analysis and risk pattern recognition
- ğŸ“‹ **Audit Trail**: Complete transaction history with compliance reporting

### ğŸ¨ **Premium User Experience**
- ğŸŒ™ **Dark Mode Interface**: Modern, eye-friendly design optimized for extended use
- ğŸ“± **Responsive Design**: Seamless experience across desktop, tablet, and mobile
- âš¡ **Progressive Loading**: Instant feedback with optimized performance
- ğŸ›ï¸ **Customizable Dashboard**: Personalized widgets and reporting views

---


### ğŸ¯ **High-Level System Overview**
```mermaid
graph TB
    A[ğŸ‘¤ User] -->|Access| B[ğŸ–¥ï¸ Streamlit UI]
    
    B -->|Screen Customer| C[ğŸ” FastAPI: /screening/realtime]
    B -->|Upload Watchlist| D[ğŸ“¤ FastAPI: /watchlist/upload]
    B -->|View Analytics| E[ğŸ“Š FastAPI: /analytics/dashboard]

    C --> F[ğŸ§  ScreeningService]
    D --> F
    E --> F

    F -->|Generate Embedding| G[ğŸ§¬ EmbeddingGenerator]
    F -->|Analyze Risk| H[âš ï¸ LLMAnalyzer]
    F -->|Calculate Metrics| I[ğŸ“ˆ AnalyticsEngine]
    F -->|Store/Retrieve Data| J[ğŸ—„ï¸ PostgreSQL + pgvector]

    J -->|Return Results| F
    F -->|Response Data| C
    C -->|Display Results| B
    D -->|Upload Status| B
    E -->|Dashboard Data| B

    %% GitHub-friendly styles for both dark & light mode
    style A fill:#1976d2,stroke:#0d47a1,stroke-width:1px
    style B fill:#7b1fa2,stroke:#4a148c,stroke-width:1px
    style C fill:#5c6bc0,stroke:#303f9f,stroke-width:1px
    style D fill:#5c6bc0,stroke:#303f9f,stroke-width:1px
    style E fill:#5c6bc0,stroke:#303f9f,stroke-width:1px
    style F fill:#f57c00,stroke:#e65100,stroke-width:1px
    style G fill:#388e3c,stroke:#1b5e20,stroke-width:1px
    style H fill:#388e3c,stroke:#1b5e20,stroke-width:1px
    style I fill:#388e3c,stroke:#1b5e20,stroke-width:1px
    style J fill:#455a64,stroke:#263238,stroke-width:1px


```

## ğŸ›ï¸ System Architecture & Technology Stack

### ğŸ¯ **Frontend Layer**
- ğŸŒ **Streamlit Framework**: Interactive web interface with real-time updates
- ğŸ¨ **Custom Styling**: Branded dark theme with intuitive navigation
- ğŸ“Š **Data Visualization**: Charts, graphs, and interactive result displays
- ğŸ”„ **State Management**: Optimized session handling and form persistence

### ğŸš€ **Backend Infrastructure**
- âš¡ **FastAPI Engine**: High-performance async API with automatic documentation
- ğŸ” **Security Layer**: JWT authentication, rate limiting, and input validation
- ğŸ“¡ **RESTful Services**: Clean API design with comprehensive error handling
- ğŸ”„ **Load Balancing**: Horizontal scaling support for enterprise deployments

### ğŸ§  **AI & Machine Learning Services**
- ğŸ¤– **Embedding Generation**: `all-MiniLM-L6-v2` transformer for semantic similarity
- ğŸ’¡ **LLM Integration**: Ollama-powered risk analysis with `gemma3:12b` model
- ğŸ” **Vector Search**: pgvector-optimized similarity matching
- ğŸ“Š **Model Pipeline**: Automated feature extraction and scoring algorithms

### ğŸ—„ï¸ **Data Management Layer**
- ğŸ˜ **PostgreSQL Core**: ACID-compliant relational database
- ğŸ” **Vector Extensions**: pgvector for high-dimensional similarity search
- ğŸ’¾ **Caching Strategy**: Redis integration for performance optimization
- ğŸ”„ **Backup & Recovery**: Automated data protection and disaster recovery

---

## ğŸ“ Project Structure & Organization

```
ğŸ¢ fincrime-namesift-llm/
â”œâ”€â”€ ğŸ“‹ config/
â”‚   â”œâ”€â”€ âš™ï¸ config.py              # Environment & application settings
â”‚   â”œâ”€â”€ ğŸ”’ security.py            # Authentication & authorization
â”‚   â””â”€â”€ ğŸ“Š logging.py             # Structured logging configuration
â”œâ”€â”€ ğŸ—„ï¸ database/
â”‚   â”œâ”€â”€ ğŸ”Œ connection.py          # Database connection management
â”‚   â”œâ”€â”€ ğŸ“‹ models.py              # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ ğŸ”„ migrations/            # Database schema versions
â”‚   â””â”€â”€ ğŸŒ± seeds/                 # Sample data for development
â”œâ”€â”€ ğŸš€ api/
â”‚   â”œâ”€â”€ ğŸŒ main.py                # FastAPI application entry point
â”‚   â”œâ”€â”€ ğŸ“¡ endpoints/             # API route definitions
â”‚   â”œâ”€â”€ ğŸ›¡ï¸ middleware/            # Request/response processing
â”‚   â””â”€â”€ âœ… validators.py          # Input validation schemas
â”œâ”€â”€ ğŸ¯ services/
â”‚   â”œâ”€â”€ ğŸ” screening.py           # Core screening business logic
â”‚   â”œâ”€â”€ ğŸ¤– embedding.py           # ML embedding generation
â”‚   â”œâ”€â”€ ğŸ’¡ llm.py                 # AI analysis & explanations
â”‚   â”œâ”€â”€ ğŸ“‹ watchlist.py           # Watchlist management
â”‚   â””â”€â”€ ğŸ“Š analytics.py           # Reporting & insights
â”œâ”€â”€ ğŸŒ frontend/
â”‚   â”œâ”€â”€ ğŸ¨ ui.py                  # Streamlit application
â”‚   â”œâ”€â”€ ğŸ“Š components/            # Reusable UI components
â”‚   â”œâ”€â”€ ğŸ­ styles/                # Custom CSS & themes
â”‚   â””â”€â”€ ğŸ“± pages/                 # Application screens
â”œâ”€â”€ ğŸ§ª tests/
â”‚   â”œâ”€â”€ ğŸ”¬ unit/                  # Unit test suites
â”‚   â”œâ”€â”€ ğŸ”— integration/           # Integration test cases
â”‚   â””â”€â”€ ğŸ­ e2e/                   # End-to-end scenarios
â”œâ”€â”€ ğŸ“š docs/
â”‚   â”œâ”€â”€ ğŸ“– api/                   # API documentation
â”‚   â”œâ”€â”€ ğŸ‘¥ user/                  # User guides & tutorials
â”‚   â””â”€â”€ ğŸ› ï¸ deployment/            # Infrastructure guides
â”œâ”€â”€ ğŸ”§ scripts/
â”‚   â”œâ”€â”€ ğŸš€ deploy.sh              # Deployment automation
â”‚   â”œâ”€â”€ ğŸŒ± seed-data.py           # Data initialization
â”‚   â””â”€â”€ ğŸ§¹ cleanup.py             # Maintenance utilities
â””â”€â”€ ğŸ“¦ requirements/
    â”œâ”€â”€ ğŸ¯ base.txt               # Core dependencies
    â”œâ”€â”€ ğŸ§ª dev.txt                # Development tools
    â””â”€â”€ ğŸš€ prod.txt               # Production requirements
```

---

## ğŸ”„ Application Workflows & Data Flow


### ğŸ” **Detailed Customer Screening Sequence**
```mermaid
sequenceDiagram
    actor User as ğŸ‘¤ User
    participant UI as ğŸ–¥ï¸ Streamlit UI
    participant API as ğŸ”Œ FastAPI
    participant SS as ğŸ§  ScreeningService
    participant EG as ğŸ§¬ EmbeddingGenerator
    participant LLM as âš ï¸ LLMAnalyzer
    participant Analytics as ğŸ“ˆ AnalyticsEngine
    participant DB as ğŸ—„ï¸ PostgreSQL

    ğŸ‘¤ User->>ğŸ–¥ï¸ Streamlit UI: Enter customer details
    ğŸ–¥ï¸ Streamlit UI->>ğŸ”Œ FastAPI: POST /screening/realtime
    ğŸ”Œ FastAPI->>ğŸ§  ScreeningService: screen_entity(name, dob, threshold)
    
    ğŸ§  ScreeningService->>ğŸ§¬ EmbeddingGenerator: generate_embedding(customer_name)
    ğŸ§¬ EmbeddingGenerator-->>ğŸ§  ScreeningService: Embedding vector (1536-dim)
    
    ğŸ§  ScreeningService->>ğŸ—„ï¸ PostgreSQL: Vector similarity search
    ğŸ—„ï¸ PostgreSQL-->>ğŸ§  ScreeningService: Potential matches with scores
    
    alt ğŸŸ¢ High-confidence matches found
        ğŸ§  ScreeningService->>âš ï¸ LLMAnalyzer: analyze_risk(customer, matches)
        âš ï¸ LLMAnalyzer-->>ğŸ§  ScreeningService: Risk explanation & confidence
        ğŸ§  ScreeningService->>ğŸ“ˆ AnalyticsEngine: update_screening_metrics()
        ğŸ§  ScreeningService->>ğŸ—„ï¸ PostgreSQL: Save ScreeningRecord + Matches
    else ğŸ”µ No significant matches
        ğŸ§  ScreeningService->>ğŸ—„ï¸ PostgreSQL: Save ScreeningRecord (clean)
        ğŸ§  ScreeningService->>ğŸ“ˆ AnalyticsEngine: update_clean_screening_stats()
    end
    
    ğŸ—„ï¸ PostgreSQL-->>ğŸ§  ScreeningService: Persistence confirmation
    ğŸ§  ScreeningService-->>ğŸ”Œ FastAPI: Comprehensive screening results
    ğŸ”Œ FastAPI-->>ğŸ–¥ï¸ Streamlit UI: JSON response with UI data
    ğŸ–¥ï¸ Streamlit UI-->>ğŸ‘¤ User: Interactive results display

```

---

## ğŸ› ï¸ Installation & Configuration Guide

### ğŸ”§ **System Requirements**
- ğŸ **Python**: 3.8+ (recommended: 3.11+)
- ğŸ—„ï¸ **Database**: PostgreSQL 14+ with pgvector extension
- ğŸ’¡ **AI Engine**: Ollama server with gemma3:12b model
- ğŸ’¾ **Memory**: Minimum 8GB RAM (16GB+ recommended)
- ğŸ’½ **Storage**: 50GB+ free space for embeddings and logs

### ğŸ“¥ **Quick Start Installation**

#### 1ï¸âƒ£ **Repository Setup**
```bash
git clone https://github.com/your-org/fincrime-namesift-llm.git
cd fincrime-namesift-llm
```

#### 2ï¸âƒ£ **Environment Configuration**
Create your `.env` file with these enhanced settings:

```env
# ğŸ—„ï¸ Database Configuration
PGUSER=screening_admin
PGPASSWORD=your_secure_password_here
PGHOST=localhost
PGPORT=5432
PGDATABASE=wlmscreening_db
DATABASE_URL=postgresql://screening_admin:your_secure_password_here@localhost:5432/wlmscreening_db

# ğŸš€ API Configuration
API_BASE_URL=http://localhost:8000
API_VERSION=v1
API_TITLE="FinCrime-NameSift-LLM Platform"
DEBUG_MODE=false
CORS_ORIGINS=http://localhost:8501,http://localhost:3000

# ğŸ’¡ AI & ML Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma3:12b
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_CACHE_SIZE=10000
SIMILARITY_THRESHOLD=0.85

# ğŸ” Security Settings
JWT_SECRET_KEY=your_jwt_secret_key_minimum_32_characters
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
API_RATE_LIMIT=100/minute

# ğŸ“Š Analytics & Monitoring
ENABLE_ANALYTICS=true
LOG_LEVEL=INFO
METRICS_ENABLED=true
PERFORMANCE_MONITORING=true

# ğŸ¯ Business Logic
DEFAULT_RISK_THRESHOLD=0.7
MAX_MATCHES_RETURNED=10
ENABLE_BATCH_PROCESSING=true
```

#### 3ï¸âƒ£ **Dependency Installation**
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install core dependencies
pip install -r requirements/base.txt

# For development
pip install -r requirements/dev.txt
```

#### 4ï¸âƒ£ **Database Initialization**
```sql
-- Connect to PostgreSQL as superuser
CREATE USER screening_admin WITH PASSWORD 'your_secure_password_here';
CREATE DATABASE wlmscreening_db OWNER screening_admin;

-- Connect to the new database
\c wlmscreening_db
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Grant permissions
GRANT ALL PRIVILEGES ON DATABASE wlmscreening_db TO screening_admin;
```

#### 5ï¸âƒ£ **AI Model Setup**
```bash
# Install and configure Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull the required model
ollama pull gemma3:12b

# Start Ollama service
ollama serve
```

### ğŸš€ **Application Launch**

#### ğŸ¯ **Development Environment**
```bash
# Terminal 1: Start the API server
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Launch the UI
streamlit run frontend/ui.py --server.port 8501

# Terminal 3: Start background workers (optional)
python scripts/worker.py
```

#### ğŸ­ **Production Deployment**
```bash
# Use Docker Compose for production
docker-compose up -d

# Or manual production setup
gunicorn api.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

---

## ğŸ“š User Guide & Best Practices

### ğŸ” **Customer Screening Workflow**

#### ğŸ¯ **Basic Screening Process**
1. ğŸŒ **Access Interface**: Navigate to `http://localhost:8501`
2. ğŸ“ **Input Customer Data**:
   - âœ… **Required**: Full customer name
   - ğŸ“… **Optional**: Date of birth (YYYY-MM-DD format)
   - ğŸŒ **Optional**: Nationality/citizenship
   - ğŸ¢ **Optional**: Business/organization affiliation
3. ğŸ›ï¸ **Configure Parameters**:
   - ğŸ¯ Risk threshold (0.1 - 1.0)
   - ğŸ“Š Maximum matches to return
   - ğŸ” Search sensitivity level
4. ğŸš€ **Execute Screening** and review results

#### ğŸ“Š **Understanding Results**
- ğŸ”´ **High Risk (0.8-1.0)**: Immediate review required
- ğŸŸ¡ **Medium Risk (0.5-0.79)**: Enhanced due diligence recommended  
- ğŸŸ¢ **Low Risk (0.1-0.49)**: Standard processing approved
- âšª **No Risk (0.0)**: Clean - no matches found

### ğŸ“‹ **Watchlist Management**

#### ğŸ“¤ **Supported Upload Formats**

**ğŸ“„ CSV Format Example:**
```csv
unique_id,name,date_of_birth,nationality,risk_category,aliases,source
WL001,John Smith,1980-01-15,US,PEP,"J. Smith;Johnny Smith",OFAC
WL002,Maria Garcia,1975-05-20,MX,SAN,"M. Garcia",UN_Sanctions
WL003,Ahmed Al-Rahman,1960-12-03,SA,AM,"A. Rahman;Ahmed Rahman",Media_Reports
```

**ğŸ”— JSON Format Example:**
```json
{
  "watchlist": [
    {
      "unique_id": "WL001",
      "name": "John Smith",
      "date_of_birth": "1980-01-15",
      "nationality": "US",
      "risk_category": "PEP",
      "aliases": ["J. Smith", "Johnny Smith"],
      "source": "OFAC",
      "last_updated": "2024-01-15T10:30:00Z"
    }
  ]
}
```

**ğŸ“‹ XML (ISO 20022) Format Example:**
```xml
<Document xmlns="http://www.iso20022.org">
  <Prsn>
    <Id><PrvtId><Othr><Id>WL001</Id></Othr></PrvtId></Id>
    <Nm>John Smith</Nm>
    <BirthDt>1980-01-15</BirthDt>
    <CtryOfRes>US</CtryOfRes>
    <RskCtgy>PEP</RskCtgy>
    <Aliases>
      <Alias>J. Smith</Alias>
      <Alias>Johnny Smith</Alias>
    </Aliases>
  </Prsn>
</Document>
```

---

## ğŸŒ API Reference & Integration

### ğŸ“¡ **Core Endpoints**

| ğŸ”— **Endpoint** | ğŸ¯ **Method** | ğŸ“ **Description** | ğŸ”§ **Authentication** |
|----------------|---------------|-------------------|---------------------|
| `/screening/realtime` | ğŸš€ POST | Real-time customer screening | ğŸ” JWT Required |
| `/screening/batch` | ğŸ“¦ POST | Bulk screening operations | ğŸ” JWT Required |
| `/watchlist/upload` | ğŸ“¤ POST | Upload watchlist data | ğŸ” JWT Required |
| `/watchlist/search` | ğŸ” GET | Search watchlist entries | ğŸ” JWT Required |
| `/analytics/dashboard` | ğŸ“Š GET | Screening statistics | ğŸ” JWT Required |
| `/health` | â¤ï¸ GET | System health check | ğŸŒ Public |

### ğŸ” **Screening API Details**

#### ğŸš€ **Real-time Screening**
```bash
POST /api/v1/screening/realtime
Content-Type: application/json
Authorization: Bearer <jwt_token>

{
  "customer": {
    "name": "John Smith",
    "date_of_birth": {
      "year": 1980,
      "month": 1,
      "day": 15
    },
    "nationality": "US",
    "additional_info": "CEO of Tech Corp"
  },
  "options": {
    "risk_threshold": 0.7,
    "max_matches": 5,
    "include_explanation": true,
    "enable_fuzzy_matching": true
  }
}
```

#### ğŸ“Š **Response Format**
```json
{
  "screening_id": "uuid-12345",
  "timestamp": "2024-01-15T10:30:00Z",
  "customer": {
    "name": "John Smith",
    "date_of_birth": "1980-01-15"
  },
  "results": {
    "overall_risk_score": 0.85,
    "risk_level": "HIGH",
    "total_matches": 2,
    "processing_time_ms": 150,
    "matches": [
      {
        "match_id": "uuid-67890",
        "watchlist_entity": {
          "unique_id": "WL001",
          "name": "John Smith",
          "risk_category": "PEP",
          "source": "OFAC"
        },
        "similarity_score": 0.95,
        "confidence_level": "HIGH",
        "explanation": "Exact name match with date of birth confirmation",
        "risk_factors": [
          "Political exposure",
          "High-profile position",
          "Recent sanctions activity"
        ]
      }
    ]
  }
}
```



### â˜ï¸ **Cloud Deployment Options**
- ğŸŒŠ **AWS**: ECS, RDS, ElastiCache
- â˜ï¸ **Azure**: Container Instances, PostgreSQL, Redis Cache  
- ğŸŒ©ï¸ **GCP**: Cloud Run, Cloud SQL, Memorystore


---

## ğŸ“Š Version History

### ğŸ·ï¸ **Current Release: v2.1.0** 
*Released: January 2025*

#### âœ¨ **New Features**
- ğŸ¤– Enhanced AI risk explanations with context
- ğŸ“Š Advanced analytics dashboard with trends
- ğŸ” Improved fuzzy matching algorithms
- ğŸŒ Multi-language name processing support


---

<div align="center">

[![Contributors](https://contrib.rocks/image?repo=Logulokesh/KinAI-Ecosystem)](https://github.com/Logulokesh/KinAI-Ecosystem/graphs/contributors)

</div>

---


## ğŸ“„ License

This project is entirely free to use â€” a contribution to the fight against financial crime ğŸ’¼, a commitment to transparency ğŸ”, and a step toward a safer financial system ğŸ’³.

---

<div align="center">

**Developed with dedication âš–ï¸ to integrity, security, and smart automation**

</div>

